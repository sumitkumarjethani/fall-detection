{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from fall_detection.fall.detection import StateDetector\n",
    "from fall_detection.pose import YoloPoseModel, PoseLandmarksGenerator\n",
    "from fall_detection.fall import PoseEmbedder, EstimatorClassifier\n",
    "from fall_detection.fall import load_pose_samples_from_dir\n",
    "from fall_detection.fall.embedding import COCO_POSE_KEYPOINTS\n",
    "from fall_detection.utils import load_image, save_image\n",
    "\n",
    "# run pipeline\n",
    "from fall_detection.fall.pipeline import Pipeline\n",
    "from fall_detection.object_detection import YoloObjectDetector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load sample image\n",
    "image = load_image(\"../data/fall-sample.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pose_model = YoloPoseModel(model_path=\"../models/yolov8n-pose.pt\")\n",
    "\n",
    "results = pose_model(image)\n",
    "\n",
    "img_out = pose_model.draw_landmarks(image, results)\n",
    "\n",
    "save_image(img_out, \"../data/img_pose_out.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "object_model = YoloObjectDetector(model_name=\"yolov8n.pt\")\n",
    "\n",
    "results = object_model(image)\n",
    "\n",
    "img_out = object_model.draw_results(image, results)\n",
    "\n",
    "save_image(img_out, \"../data/img_object_out.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate data for training\n",
    "pose_sample_generator = PoseLandmarksGenerator(\n",
    "    images_in_folder=\"./data/test_dataset\",\n",
    "    images_out_folder=\"./data/test_dataset_out\",\n",
    "    csvs_out_folder=\"./data/test_dataset_csv\",\n",
    "    per_pose_class_limit=4,\n",
    ")\n",
    "\n",
    "pose_sample_generator(pose_model=pose_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train classifier\n",
    "pose_embedder = PoseEmbedder(landmark_names=COCO_POSE_KEYPOINTS)\n",
    "\n",
    "classification_model = EstimatorClassifier(\n",
    "    estimator=make_pipeline(StandardScaler(), LogisticRegression(random_state=42)),\n",
    "    pose_embedder=pose_embedder,\n",
    ")\n",
    "\n",
    "detector = StateDetector(class_name=\"fall\", enter_threshold=8, exit_threshold=4)\n",
    "\n",
    "pose_samples = load_pose_samples_from_dir(\n",
    "    pose_embedder=pose_embedder,\n",
    "    n_dimensions=3,\n",
    "    n_landmarks=17,\n",
    "    landmarks_dir=\"./data/test_dataset_csv\",\n",
    "    file_extension=\"csv\",\n",
    "    file_separator=\",\",\n",
    ")\n",
    "classification_model.fit(pose_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run prediction\n",
    "\n",
    "pose_results = pose_model.predict(image)\n",
    "\n",
    "pose_landmarks = pose_model.results_to_pose_landmarks(\n",
    "    pose_results, image.shape[0], image.shape[1]\n",
    ")\n",
    "\n",
    "prediction = classification_model.predict(pose_landmarks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(\n",
    "    pose_model=pose_model,\n",
    "    object_model=object_model,\n",
    "    classification_model=classification_model,\n",
    "    detector=detector,\n",
    ")\n",
    "\n",
    "pipeline(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the video.\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tqdm\n",
    "from fall_detection.fall.plot import PoseClassificationVisualizer\n",
    "\n",
    "path_video_in = \"../data/uri.mp4\"\n",
    "path_video_out = \"../data/uri_out.mp4\"\n",
    "\n",
    "video_cap = cv2.VideoCapture(path_video_in)\n",
    "\n",
    "# Get some video parameters to generate output video with classificaiton.\n",
    "video_n_frames = video_cap.get(cv2.CAP_PROP_FRAME_COUNT)\n",
    "video_fps = video_cap.get(cv2.CAP_PROP_FPS)\n",
    "video_width = int(video_cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "video_height = int(video_cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "\n",
    "# Initialize renderer.\n",
    "pose_classification_visualizer = PoseClassificationVisualizer(\n",
    "    class_name=\"Fall\",\n",
    "    plot_x_max=video_n_frames,\n",
    "    plot_y_max=10,\n",
    ")\n",
    "\n",
    "out_video = cv2.VideoWriter(\n",
    "    path_video_out,\n",
    "    cv2.VideoWriter_fourcc(*\"mp4v\"),\n",
    "    video_fps,\n",
    "    (video_width, video_height),\n",
    ")\n",
    "\n",
    "frame_idx = 0\n",
    "output_frame = None\n",
    "with tqdm.tqdm(total=video_n_frames, position=0, leave=True) as pbar:\n",
    "    while True:\n",
    "        # Get next frame of the video.\n",
    "        success, input_frame = video_cap.read()\n",
    "        if not success:\n",
    "            break\n",
    "\n",
    "        # Run pose tracker.\n",
    "        input_frame = cv2.cvtColor(input_frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        output_frame = input_frame.copy()\n",
    "\n",
    "        results = pipeline(input_frame)\n",
    "\n",
    "        if results[\"classification\"] is not None:\n",
    "            # Draw classification plot and repetition counter.\n",
    "            output_frame = pose_classification_visualizer(\n",
    "                frame=output_frame,\n",
    "                pose_classification=results[\"classification\"],\n",
    "                pose_classification_filtered=results[\"smooth_classification\"],\n",
    "                detector_state=results[\"detection\"],\n",
    "            )\n",
    "\n",
    "        # Save the output frame.\n",
    "        out_video.write(cv2.cvtColor(np.array(output_frame), cv2.COLOR_RGB2BGR))\n",
    "\n",
    "        frame_idx += 1\n",
    "        pbar.update()\n",
    "\n",
    "# Close output video.\n",
    "out_video.release()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
